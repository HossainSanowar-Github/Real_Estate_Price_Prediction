{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc5a77c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numpy==1.23.1\n",
    "# !pip install pandas==1.4.3\n",
    "# !pip install matplotlib==3.3.2\n",
    "# !pip install seaborn==0.11.0\n",
    "# !pip install joblib==1.1.0\n",
    "# !pip install nltk==3.7\n",
    "# !pip install wordcloud==1.8.2.2\n",
    "# !pip install scikit_learn==1.0.2\n",
    "# !pip install scipy==1.9.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63094d9d",
   "metadata": {},
   "source": [
    "# Contents:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44adb62f",
   "metadata": {},
   "source": [
    "I. [Loading the Data:](#Loading-the-Data:)\n",
    "\n",
    "II. [Helper functions to prepare the data:](#Helper-functions-to-prepare-the-data:)\n",
    "\n",
    "III. [Test Inference:](#Test-Inference:)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411febbf",
   "metadata": {},
   "source": [
    "## Loading the Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e1e20a",
   "metadata": {},
   "source": [
    "([Contents:](#Contents:))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2139d6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows',None)\n",
    "pd.set_option('display.max_columns',None)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import time \n",
    "import re\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn import metrics\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import requests\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "import re\n",
    "from wordcloud import WordCloud\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import Counter\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d07c48d",
   "metadata": {},
   "source": [
    "## Helper functions to prepare the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5457cd4",
   "metadata": {},
   "source": [
    "([Contents:](#Contents:))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0171164e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average propery area (feature cleaning)\n",
    "def avg_property_area(x):\n",
    "    numbers = re.compile(r\"[-+]?(\\d*\\.\\d+|\\d+)\") \n",
    "    x = numbers.findall(x)\n",
    "    if len(x) == 1:\n",
    "        return np.float(x[0])\n",
    "    elif len(x) == 2:\n",
    "        return (np.float(x[0])+np.float(x[1]))/2\n",
    "    else:\n",
    "        return -99\n",
    "    \n",
    "# Outlier treatment\n",
    "def clip_outliers(df,col):\n",
    "    q_l = df[col].quantile(0.25)\n",
    "    q_h = df[col].quantile(0.95)\n",
    "    df[col] = df[col].clip(lower = q_l, upper = q_h)\n",
    "    return df    \n",
    "\n",
    "# Text cleaning\n",
    "# Preprocessing the text data\n",
    "REPLACE_BY_SPACE_RE = re.compile(\"[/(){}\\[\\]\\|@,;!]\")\n",
    "BAD_SYMBOLS_RE = re.compile(\"[^0-9a-z #+_]\")\n",
    "STOPWORDS_nlp = set(stopwords.words('english'))\n",
    "\n",
    "#Custom Stoplist\n",
    "stoplist = [\"i\",\"project\",\"living\",\"home\",'apartment',\"pune\",\"me\",\"my\",\"myself\",\"we\",\"our\",\"ours\",\"ourselves\",\"you\",\"you're\",\"you've\",\"you'll\",\"you'd\",\"your\",\n",
    "            \"yours\",\"yourself\",\"yourselves\",\"he\",\"him\",\"his\",\"himself\",\"she\",\"she's\",\"her\",\"hers\",\"herself\",\"it\",\n",
    "            \"it's\",\"its\",\"itself\",\"they\",\"them\",\"their\",\"theirs\",\"themselves\",\"what\",\"which\",\"who\",\"whom\",\"this\",\"that\",\"that'll\",\n",
    "            \"these\",\"those\",\"am\",\"is\",\"are\",\"was\",\"were\",\"be\",\"been\",\"being\",\"have\",\"has\",\"had\",\"having\",\"do\",\"does\",\"did\",\n",
    "            \"doing\",\"a\",\"an\",\"the\",\"and\",\"but\",\"if\",\"or\",\"because\",\"as\",\"until\",\"while\",\"of\",\"at\",\"by\",\"for\",\"with\",\"about\",\n",
    "            \"against\",\"between\",\"into\",\"through\",\"during\",\"before\",\"after\",\"above\",\"below\",\"to\",\"from\",\"up\",\"down\",\"in\",\"out\",\n",
    "            \"on\",\"off\",\"over\",\"under\",\"again\",\"further\",\"then\",\"once\",\"here\",\"there\",\"when\",\"where\",\"why\",\"all\",\"any\",\n",
    "            \"both\",\"each\",\"few\",\"more\",\"most\",\"other\",\"some\",\"such\",\"no\",\"nor\",\"not\",\"only\",\"own\",\"same\",\"so\",\"than\",\"too\",\n",
    "            \"very\",\"s\",\"t\",\"can\",\"will\",\"just\",\"don\",\"don't\",\"should\",\"should've\",\"now\",\"d\",\"ll\",\"m\",\"o\",\"re\",\"ve\",\"y\",\"ain\",\n",
    "            \"aren\",\"couldn\",\"didn\",\"doesn\",\"hadn\",\"hasn\",\n",
    "            \"haven\",\"isn\",\"ma\",\"mightn\",\"mustn\",\"needn\",\"shan\",\"shan't\",\n",
    "            \"shouldn\",\"wasn\",\"weren\",\"won\",\"rt\",\"rt\",\"qt\",\"for\",\n",
    "            \"the\",\"with\",\"in\",\"of\",\"and\",\"its\",\"it\",\"this\",\"i\",\"have\",\"has\",\"would\",\"could\",\"you\",\"a\",\"an\",\n",
    "            \"be\",\"am\",\"can\",\"edushopper\",\"will\",\"to\",\"on\",\"is\",\"by\",\"ive\",\"im\",\"your\",\"we\",\"are\",\"at\",\"as\",\"any\",\"ebay\",\"thank\",\"hello\",\"know\",\n",
    "            \"need\",\"want\",\"look\",\"hi\",\"sorry\",\"http\", \"https\",\"body\",\"dear\",\"hello\",\"hi\",\"thanks\",\"sir\",\"tomorrow\",\"sent\",\"send\",\"see\",\"there\",\"welcome\",\"what\",\"well\",\"us\"]\n",
    "\n",
    "STOPWORDS_nlp.update(stoplist)\n",
    "\n",
    "# Function to preprocess the text\n",
    "def text_prepare(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = text.replace(\"\\d+\",\" \") # removing digits\n",
    "    text = re.sub(r\"(?:\\@|https?\\://)\\S+\", \"\", text) #removing mentions and urls\n",
    "    text = text.lower() # lowercase text\n",
    "    text =  re.sub('[0-9]+', '', text)\n",
    "    text = REPLACE_BY_SPACE_RE.sub(\" \", text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    text = BAD_SYMBOLS_RE.sub(\" \", text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "    text = ' '.join([word for word in text.split() if word not in STOPWORDS_nlp]) # delete stopwors from text\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "# Pos counter\n",
    "def pos_counter(x,pos):\n",
    "    \"\"\"\n",
    "    Returns the count for the given parts of speech tag\n",
    "    \n",
    "    NN - Noun\n",
    "    VB - Verb\n",
    "    JJ - Adjective\n",
    "    RB - Adverb\n",
    "    \"\"\"\n",
    "    tokens = nltk.word_tokenize(x.lower())\n",
    "    tokens = [word for word in tokens if word not in STOPWORDS_nlp]\n",
    "    text = nltk.Text(tokens)\n",
    "    tags = nltk.pos_tag(text)\n",
    "    counts = Counter(tag for word,tag in tags)\n",
    "    return counts[pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66b79151",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    # Extracting State and Country separately from the Location Column\n",
    "    df['City'] = df['Location'].apply(lambda x: x.split(',')[0].lower().strip())\n",
    "    df['State'] = df['Location'].apply(lambda x: x.split(',')[1].lower().strip())\n",
    "    df['Country'] = df['Location'].apply(lambda x: x.split(',')[2].lower().strip())\n",
    "    \n",
    "    # Regex to match the numbers and create a separate column\n",
    "    numbers = re.compile(r\"[-+]?(\\d*\\.\\d+|\\d+)\") \n",
    "    df['Property Type Cleaned'] = df['Propert Type'].apply(lambda x: numbers.findall(x)[0] \n",
    "                                                           if len(numbers.findall(x)) > 0 else 0)\n",
    "    \n",
    "    # Cleaning the text columns\n",
    "    df['Sub-Area Cleaned'] = df['Sub-Area'].apply(lambda x: x.lower().strip())\n",
    "    df['Company Name Cleaned'] = df['Company Name'].apply(lambda x: x.lower().strip())\n",
    "    df['TownShip Name/ Society Name Cleaned'] = df['TownShip Name/ Society Name'].apply(lambda x: x.lower().strip())\n",
    "    df['Description Cleaned'] = df['Description'].apply(lambda x: x.lower().strip())\n",
    "    \n",
    "    \n",
    "    # Cleaning and encoding Binary Features\n",
    "    df['ClubHouse Cleaned'] = (df['ClubHouse'].apply(lambda x: x.lower().strip()).map({'yes':1, 'no':0}))\n",
    "    df['School / University in Township Cleaned'] = (df['School / University in Township ']\n",
    "                                                         .apply(lambda x: x.lower().strip()).map({'yes':1, 'no':0}))\n",
    "    df['Hospital in TownShip Cleaned'] = (df['Hospital in TownShip']\n",
    "                                                         .apply(lambda x: x.lower().strip()).map({'yes':1, 'no':0}))\n",
    "    df['Mall in TownShip Cleaned'] = (df['Mall in TownShip']\n",
    "                                                         .apply(lambda x: x.lower().strip()).map({'yes':1, 'no':0}))\n",
    "    df['Park / Jogging track Cleaned'] = (df['Park / Jogging track']\n",
    "                                                         .apply(lambda x: x.lower().strip()).map({'yes':1, 'no':0}))\n",
    "    df['Swimming Pool Cleaned'] = (df['Swimming Pool']\n",
    "                                                     .apply(lambda x: x.lower().strip()).map({'yes':1, 'no':0}))\n",
    "    df['Gym Cleaned'] = (df['Gym']\n",
    "                                 .apply(lambda x: x.lower().strip()).map({'yes':1, 'no':0})) \n",
    "    \n",
    "    \n",
    "\n",
    "    # Cleaning numerical columns\n",
    "    numbers = re.compile(r\"[-+]?(\\d*\\.\\d+|\\d+)\")     \n",
    "    df['Property Area in Sq. Ft. Cleaned'] = df['Property Area in Sq. Ft.'].apply(lambda x: avg_property_area(str(x)))\n",
    "#     df['Price in lakhs Cleaned'] = (df['Price in lakhs'].apply(lambda x: np.float(numbers.findall(str(x))[0]) \n",
    "#                                                                if len(numbers.findall(str(x)))>0 else np.nan ))\n",
    "    \n",
    "    # Selecting the requried columns\n",
    "    features = df.columns.tolist()[18:]\n",
    "    df1 = df[features]\n",
    "    df_final = df1.dropna()\n",
    "    \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "575c10a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    # outlier treatment\n",
    "    # Treating outliers in the numeric columns\n",
    "    cols_to_treat = ['Property Area in Sq. Ft. Cleaned']\n",
    "    \n",
    "    for col in cols_to_treat:\n",
    "        df = clip_outliers(df,col)\n",
    "    \n",
    "    # creating the price by sub-area feature\n",
    "    fileName = 'sub_area_price_map.pkl'\n",
    "    with open(fileName,'rb') as f:\n",
    "        sub_area_price_map = pickle.load(f)\n",
    "        \n",
    "    df['Price by sub-area'] =  df['Sub-Area Cleaned'].map(sub_area_price_map)\n",
    "    \n",
    "    # Adding the amenitites score feature\n",
    "    amenities_col = ['ClubHouse Cleaned',\n",
    "                     'School / University in Township Cleaned',\n",
    "                     'Hospital in TownShip Cleaned',\n",
    "                     'Mall in TownShip Cleaned',\n",
    "                     'Park / Jogging track Cleaned',\n",
    "                     'Swimming Pool Cleaned',\n",
    "                     'Gym Cleaned']\n",
    "    temp = df[amenities_col]\n",
    "    temp['Amenities score'] = temp.sum(axis=1)\n",
    "    df['Amenities score'] = temp['Amenities score']\n",
    "    \n",
    "    # creating the price by amenities score feature\n",
    "    fileName = 'amenities_score_price_map.pkl'\n",
    "    with open(fileName,'rb') as f:\n",
    "        amenities_score_price_map = pickle.load(f)  \n",
    "        \n",
    "    df['Price by Amenities score'] =  df['Amenities score'].map(amenities_score_price_map)\n",
    "    \n",
    "    # cleaning the description column and creating pos features\n",
    "    df[\"Description Cleaned\"] =  df[\"Description Cleaned\"].astype(str).apply(text_prepare)\n",
    "    df['Noun_Counts'] = df['Description Cleaned'].apply(lambda x: pos_counter(x,'NN'))\n",
    "    df['Verb_Counts'] = df['Description Cleaned'].apply(lambda x: (pos_counter(x,'VB')+pos_counter(x,'RB')))\n",
    "    df['Adjective_Counts'] = df['Description Cleaned'].apply(lambda x: pos_counter(x,'JJ'))\n",
    "    \n",
    "    # Ngram features\n",
    "    fileName = 'count_vectorizer.pkl'\n",
    "    with open(fileName,'rb') as f:\n",
    "        cv_object = pickle.load(f)\n",
    "    \n",
    "    X = cv_object.transform(df['Description Cleaned'])\n",
    "    df_ngram = pd.DataFrame(X.toarray(),columns=cv_object.get_feature_names())\n",
    "     \n",
    "    # Adding this to the main dataframe\n",
    "    df_final = pd.concat([df.reset_index(drop=True),df_ngram.reset_index(drop=True)],axis=1)\n",
    "    \n",
    "    # selecting the final model ready features\n",
    "    fileName = 'raw_features_mapping.pkl'\n",
    "    with open(fileName,'rb') as f:\n",
    "        feature_mapping = pickle.load(f)   \n",
    "        \n",
    "    fileName = 'features.pkl'\n",
    "    with open(fileName,'rb') as f:\n",
    "        feature_list = pickle.load(f)           \n",
    "    \n",
    "    # Removing price column as it is not available in test data\n",
    "    feature_list.remove('Price_in_lakhs')\n",
    "\n",
    "    df_final = df_final.rename(columns=feature_mapping)\n",
    "    df_final = df_final[feature_list]\n",
    "    \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94ebc33",
   "metadata": {},
   "source": [
    "## Test Inference:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84f7acf",
   "metadata": {},
   "source": [
    "([Contents:](#Contents:))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f014dbd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sr. No.</th>\n",
       "      <th>Location</th>\n",
       "      <th>Sub-Area</th>\n",
       "      <th>Propert Type</th>\n",
       "      <th>Property Area in Sq. Ft.</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>TownShip Name/ Society Name</th>\n",
       "      <th>Total TownShip Area in Acres</th>\n",
       "      <th>ClubHouse</th>\n",
       "      <th>School / University in Township</th>\n",
       "      <th>Hospital in TownShip</th>\n",
       "      <th>Mall in TownShip</th>\n",
       "      <th>Park / Jogging track</th>\n",
       "      <th>Swimming Pool</th>\n",
       "      <th>Gym</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Pune, Maharashtra, India</td>\n",
       "      <td>Bavdhan</td>\n",
       "      <td>1 BHK</td>\n",
       "      <td>492</td>\n",
       "      <td>Shapoorji Paloonji</td>\n",
       "      <td>Vanaha</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Shapoorji Paloonji comunity located in the sub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Pune, Maharashtra, India</td>\n",
       "      <td>Bavdhan</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>774</td>\n",
       "      <td>Shapoorji Paloonji</td>\n",
       "      <td>Vanaha</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Vanaha Township located near the lonavala hill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Pune, Maharashtra, India</td>\n",
       "      <td>Bavdhan</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>889</td>\n",
       "      <td>Shapoorji Paloonji</td>\n",
       "      <td>Vanaha</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Vanaha Society is suitable for all aged group ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Pune, Maharashtra, India</td>\n",
       "      <td>Bavdhan</td>\n",
       "      <td>3 BHK Grand</td>\n",
       "      <td>1018</td>\n",
       "      <td>Shapoorji Paloonji</td>\n",
       "      <td>Vanaha</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Vanaha township are offering 3BHK grand prpoer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Pune, Maharashtra, India</td>\n",
       "      <td>Mahalunge</td>\n",
       "      <td>2BHK</td>\n",
       "      <td>743</td>\n",
       "      <td>Godrej Properties</td>\n",
       "      <td>Godrej Hills retreat</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>The area is a hub of prestigious schools like ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sr. No.                  Location   Sub-Area Propert Type  \\\n",
       "0        1  Pune, Maharashtra, India    Bavdhan        1 BHK   \n",
       "1        2  Pune, Maharashtra, India    Bavdhan        2 BHK   \n",
       "2        3  Pune, Maharashtra, India    Bavdhan        3 BHK   \n",
       "3        4  Pune, Maharashtra, India    Bavdhan  3 BHK Grand   \n",
       "4        5  Pune, Maharashtra, India  Mahalunge         2BHK   \n",
       "\n",
       "  Property Area in Sq. Ft.        Company Name TownShip Name/ Society Name  \\\n",
       "0                      492  Shapoorji Paloonji                     Vanaha    \n",
       "1                      774  Shapoorji Paloonji                     Vanaha    \n",
       "2                      889  Shapoorji Paloonji                     Vanaha    \n",
       "3                     1018  Shapoorji Paloonji                     Vanaha    \n",
       "4                      743   Godrej Properties        Godrej Hills retreat   \n",
       "\n",
       "   Total TownShip Area in Acres ClubHouse School / University in Township   \\\n",
       "0                        1000.0       Yes                              Yes   \n",
       "1                        1000.0       Yes                              Yes   \n",
       "2                        1000.0       Yes                              Yes   \n",
       "3                        1000.0       Yes                              Yes   \n",
       "4                         100.0       Yes                              Yes   \n",
       "\n",
       "  Hospital in TownShip Mall in TownShip Park / Jogging track Swimming Pool  \\\n",
       "0                  Yes              Yes                  Yes           Yes   \n",
       "1                  Yes              Yes                  Yes           Yes   \n",
       "2                  Yes              Yes                  Yes           Yes   \n",
       "3                  Yes              Yes                  Yes           Yes   \n",
       "4                  Yes              Yes                  Yes           Yes   \n",
       "\n",
       "   Gym                                        Description  \n",
       "0  Yes  Shapoorji Paloonji comunity located in the sub...  \n",
       "1  Yes  Vanaha Township located near the lonavala hill...  \n",
       "2  Yes  Vanaha Society is suitable for all aged group ...  \n",
       "3  Yes  Vanaha township are offering 3BHK grand prpoer...  \n",
       "4  Yes  The area is a hub of prestigious schools like ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the data\n",
    "data= pd.read_excel('../real_state_/data/Pune Real Estate Data.xlsx')\n",
    "data = data.drop(['Price in Millions','Price in lakhs'],axis=1)\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "861af979",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocess = preprocess(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce21d47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Property Type Cleaned</th>\n",
       "      <th>Sub-Area Cleaned</th>\n",
       "      <th>Company Name Cleaned</th>\n",
       "      <th>TownShip Name/ Society Name Cleaned</th>\n",
       "      <th>Description Cleaned</th>\n",
       "      <th>ClubHouse Cleaned</th>\n",
       "      <th>School / University in Township Cleaned</th>\n",
       "      <th>Hospital in TownShip Cleaned</th>\n",
       "      <th>Mall in TownShip Cleaned</th>\n",
       "      <th>Park / Jogging track Cleaned</th>\n",
       "      <th>Swimming Pool Cleaned</th>\n",
       "      <th>Gym Cleaned</th>\n",
       "      <th>Property Area in Sq. Ft. Cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>india</td>\n",
       "      <td>1</td>\n",
       "      <td>bavdhan</td>\n",
       "      <td>shapoorji paloonji</td>\n",
       "      <td>vanaha</td>\n",
       "      <td>shapoorji paloonji comunity located in the sub...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>492.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>india</td>\n",
       "      <td>2</td>\n",
       "      <td>bavdhan</td>\n",
       "      <td>shapoorji paloonji</td>\n",
       "      <td>vanaha</td>\n",
       "      <td>vanaha township located near the lonavala hill...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>774.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>india</td>\n",
       "      <td>3</td>\n",
       "      <td>bavdhan</td>\n",
       "      <td>shapoorji paloonji</td>\n",
       "      <td>vanaha</td>\n",
       "      <td>vanaha society is suitable for all aged group ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>889.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>india</td>\n",
       "      <td>3</td>\n",
       "      <td>bavdhan</td>\n",
       "      <td>shapoorji paloonji</td>\n",
       "      <td>vanaha</td>\n",
       "      <td>vanaha township are offering 3bhk grand prpoer...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1018.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>india</td>\n",
       "      <td>2</td>\n",
       "      <td>mahalunge</td>\n",
       "      <td>godrej properties</td>\n",
       "      <td>godrej hills retreat</td>\n",
       "      <td>the area is a hub of prestigious schools like ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>743.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Country Property Type Cleaned Sub-Area Cleaned Company Name Cleaned  \\\n",
       "0   india                     1          bavdhan   shapoorji paloonji   \n",
       "1   india                     2          bavdhan   shapoorji paloonji   \n",
       "2   india                     3          bavdhan   shapoorji paloonji   \n",
       "3   india                     3          bavdhan   shapoorji paloonji   \n",
       "4   india                     2        mahalunge    godrej properties   \n",
       "\n",
       "  TownShip Name/ Society Name Cleaned  \\\n",
       "0                              vanaha   \n",
       "1                              vanaha   \n",
       "2                              vanaha   \n",
       "3                              vanaha   \n",
       "4                godrej hills retreat   \n",
       "\n",
       "                                 Description Cleaned  ClubHouse Cleaned  \\\n",
       "0  shapoorji paloonji comunity located in the sub...                  1   \n",
       "1  vanaha township located near the lonavala hill...                  1   \n",
       "2  vanaha society is suitable for all aged group ...                  1   \n",
       "3  vanaha township are offering 3bhk grand prpoer...                  1   \n",
       "4  the area is a hub of prestigious schools like ...                  1   \n",
       "\n",
       "   School / University in Township Cleaned  Hospital in TownShip Cleaned  \\\n",
       "0                                        1                             1   \n",
       "1                                        1                             1   \n",
       "2                                        1                             1   \n",
       "3                                        1                             1   \n",
       "4                                        1                             1   \n",
       "\n",
       "   Mall in TownShip Cleaned  Park / Jogging track Cleaned  \\\n",
       "0                         1                             1   \n",
       "1                         1                             1   \n",
       "2                         1                             1   \n",
       "3                         1                             1   \n",
       "4                         1                             1   \n",
       "\n",
       "   Swimming Pool Cleaned  Gym Cleaned  Property Area in Sq. Ft. Cleaned  \n",
       "0                      1            1                             492.0  \n",
       "1                      1            1                             774.0  \n",
       "2                      1            1                             889.0  \n",
       "3                      1            1                            1018.0  \n",
       "4                      1            1                             743.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_preprocess.shape)\n",
    "df_preprocess.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3252108",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = create_features(df_preprocess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17851168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 25)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PropertyType</th>\n",
       "      <th>ClubHouse</th>\n",
       "      <th>School_University_in_Township</th>\n",
       "      <th>Hospital_in_TownShip</th>\n",
       "      <th>Mall_in_TownShip</th>\n",
       "      <th>Park_Jogging_track</th>\n",
       "      <th>Swimming_Pool</th>\n",
       "      <th>Gym</th>\n",
       "      <th>Property_Area_in_Sq_Ft</th>\n",
       "      <th>Price_by_sub_area</th>\n",
       "      <th>Amenities_score</th>\n",
       "      <th>Price_by_Amenities_score</th>\n",
       "      <th>Noun_Counts</th>\n",
       "      <th>Verb_Counts</th>\n",
       "      <th>Adjective_Counts</th>\n",
       "      <th>boasts_elegant</th>\n",
       "      <th>elegant_towers</th>\n",
       "      <th>every_day</th>\n",
       "      <th>great_community</th>\n",
       "      <th>mantra_gold</th>\n",
       "      <th>offering_bedroom</th>\n",
       "      <th>quality_specification</th>\n",
       "      <th>stories_offering</th>\n",
       "      <th>towers_stories</th>\n",
       "      <th>world_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>670.0</td>\n",
       "      <td>58.044000</td>\n",
       "      <td>7</td>\n",
       "      <td>72.666667</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>774.0</td>\n",
       "      <td>58.044000</td>\n",
       "      <td>7</td>\n",
       "      <td>72.666667</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>889.0</td>\n",
       "      <td>58.044000</td>\n",
       "      <td>7</td>\n",
       "      <td>72.666667</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>58.044000</td>\n",
       "      <td>7</td>\n",
       "      <td>72.666667</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>743.0</td>\n",
       "      <td>73.555556</td>\n",
       "      <td>7</td>\n",
       "      <td>72.666667</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PropertyType  ClubHouse  School_University_in_Township  \\\n",
       "0            1          1                              1   \n",
       "1            2          1                              1   \n",
       "2            3          1                              1   \n",
       "3            3          1                              1   \n",
       "4            2          1                              1   \n",
       "\n",
       "   Hospital_in_TownShip  Mall_in_TownShip  Park_Jogging_track  Swimming_Pool  \\\n",
       "0                     1                 1                   1              1   \n",
       "1                     1                 1                   1              1   \n",
       "2                     1                 1                   1              1   \n",
       "3                     1                 1                   1              1   \n",
       "4                     1                 1                   1              1   \n",
       "\n",
       "   Gym  Property_Area_in_Sq_Ft  Price_by_sub_area  Amenities_score  \\\n",
       "0    1                   670.0          58.044000                7   \n",
       "1    1                   774.0          58.044000                7   \n",
       "2    1                   889.0          58.044000                7   \n",
       "3    1                  1018.0          58.044000                7   \n",
       "4    1                   743.0          73.555556                7   \n",
       "\n",
       "   Price_by_Amenities_score  Noun_Counts  Verb_Counts  Adjective_Counts  \\\n",
       "0                 72.666667            9            1                 3   \n",
       "1                 72.666667            9            1                 3   \n",
       "2                 72.666667            9            1                 3   \n",
       "3                 72.666667            8            1                 3   \n",
       "4                 72.666667           12            1                 6   \n",
       "\n",
       "   boasts_elegant  elegant_towers  every_day  great_community  mantra_gold  \\\n",
       "0               0               0          0                0            0   \n",
       "1               0               0          0                0            0   \n",
       "2               0               0          0                0            0   \n",
       "3               0               0          0                0            0   \n",
       "4               0               0          0                0            0   \n",
       "\n",
       "   offering_bedroom  quality_specification  stories_offering  towers_stories  \\\n",
       "0                 0                      0                 0               0   \n",
       "1                 0                      0                 0               0   \n",
       "2                 0                      0                 0               0   \n",
       "3                 0                      0                 0               0   \n",
       "4                 0                      0                 0               0   \n",
       "\n",
       "   world_class  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_features.shape)\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a70bdcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PropertyType',\n",
       " 'ClubHouse',\n",
       " 'School_University_in_Township',\n",
       " 'Hospital_in_TownShip',\n",
       " 'Mall_in_TownShip']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = df_features.columns.tolist()\n",
    "columns[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05cd26f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = df_features.iloc[3].to_dict()\n",
    "#Even if an integer of the type int64 is present in another object like a dictionary, \n",
    "#the TypeError exception will occur with the message “TypeError: Object of type int64 is not JSON serializable”\n",
    "import json\n",
    "# define a class to avoid that\n",
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return super(NpEncoder, self).default(obj)\n",
    "    \n",
    "payload = json.dumps(payload,cls=NpEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88e481b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"PropertyType\": \"3\", \"ClubHouse\": 1, \"School_University_in_Township\": 1, \"Hospital_in_TownShip\": 1, \"Mall_in_TownShip\": 1, \"Park_Jogging_track\": 1, \"Swimming_Pool\": 1, \"Gym\": 1, \"Property_Area_in_Sq_Ft\": 1018.0, \"Price_by_sub_area\": 58.044000000000004, \"Amenities_score\": 7, \"Price_by_Amenities_score\": 72.66666666666667, \"Noun_Counts\": 8, \"Verb_Counts\": 1, \"Adjective_Counts\": 3, \"boasts_elegant\": 0, \"elegant_towers\": 0, \"every_day\": 0, \"great_community\": 0, \"mantra_gold\": 0, \"offering_bedroom\": 0, \"quality_specification\": 0, \"stories_offering\": 0, \"towers_stories\": 0, \"world_class\": 0}'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcaba053",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = df_features.iloc[3].to_dict()\n",
    "payload = json.dumps(payload,cls=NpEncoder)\n",
    "\n",
    "out =  requests.post(url='https://property-price-prediction-live.herokuapp.com/predict',\n",
    "                data=payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c1589e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"[85.55245708]\"'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce7cc26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []\n",
    "for i in range(len(df_features)):\n",
    "    payload = df_features.iloc[i].to_dict()\n",
    "    payload = json.dumps(payload,cls=NpEncoder)\n",
    "    \n",
    "    out =  requests.post(url='https://property-price-prediction-live.herokuapp.com/predict',\n",
    "                    data=payload)\n",
    "    result = np.float(re.sub('[^A-Za-z0-9.]+', '', out.text))  \n",
    "    output.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57886dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[41.73696173,\n",
       " 57.70878214,\n",
       " 74.58849812,\n",
       " 85.55245708,\n",
       " 66.79123803,\n",
       " 84.59893199,\n",
       " 77.66213533,\n",
       " 108.16028495,\n",
       " 78.39072133,\n",
       " 109.57364513,\n",
       " 159.10621088,\n",
       " 176.79921586,\n",
       " 173.62768353,\n",
       " 82.30834029,\n",
       " 118.12537567,\n",
       " 50.24301879,\n",
       " 57.96254756,\n",
       " 79.05972822,\n",
       " 52.32957137,\n",
       " 69.86078406,\n",
       " 74.73422689,\n",
       " 103.96509677,\n",
       " 38.42625687,\n",
       " 62.09826553,\n",
       " 52.03298601,\n",
       " 56.40783384,\n",
       " 67.41405046,\n",
       " 88.43816135,\n",
       " 71.24488624,\n",
       " 73.88559514,\n",
       " 83.5413806,\n",
       " 84.88514865,\n",
       " 103.69906684,\n",
       " 102.73270284,\n",
       " 115.79059498,\n",
       " 61.73645075,\n",
       " 106.18832373,\n",
       " 85.2035976,\n",
       " 119.28481463,\n",
       " 42.50511413,\n",
       " 74.52375717,\n",
       " 143.78489959,\n",
       " 30.68352346,\n",
       " 37.17655204,\n",
       " 41.66563326,\n",
       " 84.43268267,\n",
       " 87.32860919,\n",
       " 115.21966742,\n",
       " 109.0564247,\n",
       " 123.23834368,\n",
       " 168.31854671,\n",
       " 42.84774364,\n",
       " 51.65022681,\n",
       " 55.37759299,\n",
       " 65.17603304,\n",
       " 60.00438345,\n",
       " 48.02535026,\n",
       " 58.46073342,\n",
       " 64.29291026,\n",
       " 56.84451424,\n",
       " 86.81352401,\n",
       " 42.71811613,\n",
       " 53.57938083,\n",
       " 71.38925869,\n",
       " 68.10531012,\n",
       " 89.62387405,\n",
       " 80.54255645,\n",
       " 198.02413568,\n",
       " 206.04585597,\n",
       " 71.86346632,\n",
       " 75.42780719,\n",
       " 68.29750563,\n",
       " 71.6028411,\n",
       " 101.65920588,\n",
       " 98.28978398,\n",
       " 49.31402349,\n",
       " 58.67832153,\n",
       " 65.44468952,\n",
       " 101.17783324,\n",
       " 70.94985793,\n",
       " 92.79167626,\n",
       " 100.56553118,\n",
       " 36.69869583,\n",
       " 41.03465445,\n",
       " 57.51660476,\n",
       " 129.13718503,\n",
       " 104.83352665,\n",
       " 56.81860231,\n",
       " 54.15596765,\n",
       " 54.0140884,\n",
       " 52.78332523,\n",
       " 54.99632164,\n",
       " 147.1047694,\n",
       " 151.06983648,\n",
       " 158.17612746,\n",
       " 171.80572794,\n",
       " 184.14667896,\n",
       " 185.42457951,\n",
       " 62.6327785,\n",
       " 80.45007225,\n",
       " 87.38493708,\n",
       " 88.82832672,\n",
       " 114.71905331,\n",
       " 118.52342566,\n",
       " 133.89414118,\n",
       " 127.78941741,\n",
       " 49.82525388,\n",
       " 53.14347139,\n",
       " 41.20612597,\n",
       " 49.22784625,\n",
       " 48.46613121,\n",
       " 46.9374395,\n",
       " 47.70178535,\n",
       " 66.77560635,\n",
       " 99.57873886,\n",
       " 99.76561911,\n",
       " 104.72261629,\n",
       " 132.78680943,\n",
       " 143.78560808,\n",
       " 68.63605051,\n",
       " 88.45795607,\n",
       " 78.32650261,\n",
       " 91.80755637,\n",
       " 73.25928293,\n",
       " 70.71176549,\n",
       " 75.16217959,\n",
       " 101.13640178,\n",
       " 125.79157006,\n",
       " 156.31923186,\n",
       " 71.43341516,\n",
       " 69.13488019,\n",
       " 167.61816787,\n",
       " 54.22598083,\n",
       " 56.35135397,\n",
       " 64.0215926,\n",
       " 95.02977235,\n",
       " 91.6406071,\n",
       " 103.22321155,\n",
       " 131.98194994,\n",
       " 127.53614369,\n",
       " 135.76576043,\n",
       " 55.67023468,\n",
       " 64.32300233,\n",
       " 67.35364023,\n",
       " 88.65141817,\n",
       " 114.40368235,\n",
       " 69.98262209,\n",
       " 72.63450426,\n",
       " 80.3732065,\n",
       " 61.07579212,\n",
       " 60.83163938,\n",
       " 50.25739822,\n",
       " 52.82766646,\n",
       " 78.02168578,\n",
       " 80.09280294,\n",
       " 41.21853188,\n",
       " 46.27259709,\n",
       " 62.4600622,\n",
       " 92.84558114,\n",
       " 98.57878141,\n",
       " 99.41249173,\n",
       " 46.16730005,\n",
       " 58.74478641,\n",
       " 44.42937561,\n",
       " 52.42470837,\n",
       " 77.68093174,\n",
       " 81.77121323,\n",
       " 187.80992054,\n",
       " 199.21588711,\n",
       " 58.85402194,\n",
       " 81.20990984,\n",
       " 69.98181477,\n",
       " 99.05021164,\n",
       " 63.77388586,\n",
       " 47.40959022,\n",
       " 43.85190372,\n",
       " 45.8836447,\n",
       " 44.48565898,\n",
       " 56.04043329,\n",
       " 64.54846529,\n",
       " 71.17383046,\n",
       " 70.0195556,\n",
       " 146.50860221,\n",
       " 180.87147588,\n",
       " 188.94860414,\n",
       " 42.68429272,\n",
       " 42.28738761,\n",
       " 44.07964764,\n",
       " 56.25191475,\n",
       " 52.36277989,\n",
       " 46.44201944,\n",
       " 28.66659645,\n",
       " 28.94623141,\n",
       " 95.36841668,\n",
       " 127.8689963,\n",
       " 148.92776178,\n",
       " 175.39909445,\n",
       " 93.18527057,\n",
       " 131.97620132,\n",
       " 100.7738478]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71224973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data= pd.read_excel(r'../data/Pune Real Estate Data.xlsx')\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da48222b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_interval(interval_estimate, prediction):\n",
    "    '''\n",
    "    Get a prediction interval for a linear regression model.\n",
    "    \n",
    "    INPUTS: \n",
    "        - interval_estimate based on the final model's performance on the training data \n",
    "        - predicted values for the test data,\n",
    "        - Prediction interval threshold (default = .95) \n",
    "    OUTPUT: \n",
    "        - Prediction interval for single test prediction\n",
    "    '''\n",
    "    \n",
    "    #generate prediction interval lower and upper bound cs_24\n",
    "    lower, upper = prediction - interval_estimate, prediction + interval_estimate\n",
    "    return lower, upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed47ddc9",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'model/interval_est.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/70/xyz7khq54gx8qklx52wtt6tw0000gn/T/ipykernel_42989/1487600342.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfileName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'model/interval_est.pkl'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileName\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0minterval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'model/interval_est.pkl'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "fileName = 'model/interval_est.pkl'\n",
    "with open(fileName,'rb') as f:\n",
    "    interval = pickle.load(f)\n",
    "\n",
    "interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4ad1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting prediction intervals for the test data\n",
    "lower_vet = []\n",
    "upper_vet = []\n",
    "\n",
    "for out in output:\n",
    "    lower, upper =  get_prediction_interval(interval,out)\n",
    "    lower_vet.append(lower)\n",
    "    upper_vet.append(upper)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dba16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(zip(lower_vet,upper_vet,output),columns=['lower','upper','mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ffe3e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "7e8cbc31db87ef66faa56dc0153a3cc0cf513f996ecefcaa36993899447d62a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
